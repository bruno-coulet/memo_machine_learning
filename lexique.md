A :

Accuracy (Exactitude) : Mesure des prédictions correctes divisée par le nombre total de prédictions.

Aire sous la courbe (Area Under Curve - AUC) : Métrique représentant l'aire sous la courbe ROC (Receiver Operating Characteristic), utilisée pour évaluer les modèles de classification.

ARIMA : Acronyme de Autoregressive Integrated Moving Average (Moyenne mobile intégrée autorégressive), une méthode de prévision de séries temporelles.

B :

Biais (Bias) : Différence entre la valeur attendue des prédictions d'un modèle et la valeur réelle.

Théorème de Bayes (Bayes Theorem) : Formule de probabilité qui calcule la vraisemblance d'un événement en se basant sur des connaissances préalables.

Loi binomiale (Binomial Distribution) : Distribution de probabilité qui modélise le nombre de succès dans un nombre fixe d'essais de Bernoulli indépendants.

C :

Clustering (ou Regroupement) : Action de regrouper des points de données en fonction de leurs similarités.

Matrice de confusion (Confusion Matrix) : Tableau utilisé pour évaluer la performance d'un modèle de classification.

Validation croisée (Cross-validation) : Technique pour évaluer la performance d'un modèle en divisant les données en sous-ensembles pour l'entraînement et le test.

D :

Arbres de décision (Decision Trees) : Modèle en forme d'arbre utilisé pour des tâches de classification et de régression.

Réduction de dimensionnalité (Dimensionality Reduction) : Processus de réduction du nombre de caractéristiques (features) dans un jeu de données tout en préservant les informations importantes.

Modèles discriminatifs (Discriminative Models) : Modèles qui apprennent la frontière entre différentes classes.

E : 

Apprentissage ensembliste (Ensemble Learning) : Technique qui combine plusieurs modèles pour améliorer la performance prédictive.

Analyse exploratoire des données (EDA - Exploratory Data Analysis) : Processus d'analyse et de visualisation des données pour comprendre leurs patterns et propriétés.

Entropie (Entropy) : Mesure de l'incertitude ou du désordre dans l'information.

F :

Ingénierie des caractéristiques (Feature Engineering) : Processus de création de nouvelles caractéristiques (features) à partir de données existantes pour améliorer la performance du modèle.

Score F (F-score) : Métrique qui établit un équilibre entre la précision et le rappel (precision et recall) pour la classification binaire.

Extraction de caractéristiques (Feature Extraction) : Processus d'extraction automatique de caractéristiques significatives à partir des données.

G :

Descente de gradient (Gradient Descent) : Algorithme d'optimisation utilisé pour minimiser une fonction en ajustant les paramètres de manière itérative.

Loi de Gauss (Gaussian Distribution) : Distribution normale, avec une fonction de densité de probabilité en forme de cloche.

Gradient Boosting : Méthode d'apprentissage ensembliste qui construit séquentiellement plusieurs apprenants faibles.

H :

Hypothèse (Hypothesis) : Affirmation ou supposition testable en inférence statistique.

Clustering hiérarchique (Hierarchical Clustering) : Méthode de regroupement qui organise les données dans une structure arborescente.

Hétéroscédasticité (Heteroscedasticity) : Variance inégale des erreurs dans un modèle de régression.

I :

Gain d'information (Information Gain) : Mesure utilisée dans les arbres de décision pour déterminer l'importance d'une caractéristique (feature).

Variable indépendante (Independent Variable) : Variable qui est manipulée dans une expérience pour observer son effet sur la variable dépendante.

Déséquilibre (Imbalance) : Situation où la distribution des classes dans un jeu de données n'est pas égale.

J :

Jupyter : Environnement de calcul interactif utilisé pour l'analyse de données et le machine learning.

Probabilité conjointe (Joint Probability) : Probabilité que deux ou plusieurs événements se produisent simultanément.

Indice de Jaccard (Jaccard Index) : Mesure de similarité entre deux ensembles.

K :

Estimation de la densité par noyau (Kernel Density Estimation) : Méthode non paramétrique pour estimer la fonction de densité de probabilité d'une variable aléatoire continue.

Test de Kolmogorov-Smirnov (Test KS) : Test non paramétrique pour comparer deux distributions de probabilité.

Clustering K-Means (KMeans Clustering) : Partitionnement des données en K clusters en fonction de la similarité.

L :

Vraisemblance (Likelihood) : Probabilité d'observer les données étant donné un modèle spécifique.

Régression linéaire (Linear Regression) : Méthode statistique pour modéliser la relation entre des variables dépendantes et indépendantes.

Régularisation L1/L2 (L1/L2 Regularization) : Techniques pour prévenir le surapprentissage (overfitting) en ajoutant des termes de pénalité à la fonction de perte du modèle.

M :

Estimation du maximum de vraisemblance (Maximum Likelihood Estimation) : Méthode pour estimer les paramètres d'un modèle statistique.

Multicolinéarité (Multicollinearity) : Situation où deux ou plusieurs variables indépendantes sont fortement corrélées dans un modèle de régression.

Information mutuelle (Mutual Information) : Mesure de la quantité d'information partagée entre deux variables.

N :

Classifieur bayésien naïf (Naive Bayes) : Classifieur probabiliste basé sur le théorème de Bayes avec l'hypothèse d'indépendance des caractéristiques (features).

Normalisation (Normalization) : Mise à l'échelle des données pour qu'elles aient une moyenne de 0 et un écart-type de 1.

Hypothèse nulle (Null Hypothesis) : Hypothèse d'absence de différence significative ou d'effet dans un test statistique.

O :

Surapprentissage (Overfitting) : Se produit lorsqu'un modèle est performant sur les données d'entraînement mais mauvais sur de nouvelles données.

Valeurs aberrantes (Outliers) : Points de données qui diffèrent considérablement des autres points dans un jeu de données.

Encodage one-hot (One-hot encoding) : Processus de conversion de variables catégorielles en vecteurs binaires.

P :

Analyse en Composantes Principales (ACP ou PCA) : Technique de réduction de dimensionnalité pour transformer des données en composantes orthogonales.

Précision (Precision) : Proportion des prédictions positives qui sont réellement positives dans un modèle de classification.

p-value : Probabilité d'observer un résultat au moins aussi extrême que celui obtenu, si l'hypothèse nulle est vraie.

Q :

Diagramme Quantile-Quantile (QQ-plot) : Outil graphique pour comparer la distribution de deux jeux de données.

Décomposition QR (QR decomposition) : Factorisation d'une matrice en une matrice orthogonale et une matrice triangulaire supérieure.

R :

Forêt d'arbres décisionnels (Random Forest) : Méthode d'apprentissage ensembliste utilisant plusieurs arbres de décision pour faire des prédictions.

Rappel (Recall) : Proportion des instances positives réelles qui ont été correctement identifiées par le modèle.

Courbe ROC (Receiver Operating Characteristic Curve) : Graphique montrant la performance d'un classifieur binaire à différents seuils.

S :

Machine à vecteurs de support (SVM - Support Vector Machine) : Algorithme de machine learning supervisé utilisé pour la classification et la régression.

Standardisation (Standardisation) : Mise à l'échelle des données pour qu'elles aient une moyenne de 0 et un écart-type de 1.

Échantillonnage (Sampling) : Processus de sélection d'un sous-ensemble de points de données à partir d'un jeu de données plus large.

T :

t-SNE (t-Distributed Stochastic Neighbor Embedding) : Technique de réduction de dimensionnalité pour visualiser des données de haute dimension dans des dimensions inférieures.

Loi de Student (t-distribution) : Distribution de probabilité utilisée dans les tests d'hypothèses lorsque la taille de l'échantillon est petite.

Erreur de type I/II (Type I/II Error) : L'erreur de type I est un faux positif, et l'erreur de type II est un faux négatif dans un test d'hypothèse.

U :

Sous-apprentissage (Underfitting) : Se produit lorsqu'un modèle est trop simple pour capturer les motifs sous-jacents des données.

UMAP (Uniform Manifold Approximation and Projection) : Technique de réduction de dimensionnalité pour la visualisation de données de haute dimension.

Loi uniforme (Uniform Distribution) : Distribution de probabilité où toutes les issues sont équiprobables.

V :

Variance : Mesure de la dispersion des points de données autour de la moyenne.

Courbe de validation (Validation Curve) : Graphique montrant comment la performance d'un modèle évolue avec différentes valeurs d'hyperparamètres.

Disparition du gradient (Vanishing Gradient) : Problème dans les réseaux de neurones profonds où les gradients deviennent très petits pendant l'entraînement.

W :

Plongement de mots (Word embedding) : Représentation de mots sous forme de vecteurs denses en traitement du langage naturel.

Nuage de mots (Word cloud) : Visualisation de données textuelles où la fréquence des mots est représentée par leur taille.

Poids (Weights) : Paramètres qui sont appris par un modèle de machine learning pendant l'entraînement.

X :

XGBoost (Extreme Gradient Boosting) : Bibliothèque populaire de gradient boosting.

XLNet : Modèle de langage basé sur un pré-entraînement autorégressif généralisé de type Transformer.

Y :

YOLO (You Only Look Once) : Système de détection d'objets en temps réel.

Yellowbrick : Bibliothèque Python pour la visualisation et le diagnostic en machine learning.

Z :

Score Z (Z-score) : Valeur standardisée représentant à combien d'écarts-types un point de données se situe de la moyenne.

Test Z (Z-test) : Test statistique utilisé pour comparer la moyenne d'un échantillon à la moyenne connue d'une population.

Apprentissage zéro-shot (Zero-shot learning) : Méthode de machine learning où un modèle peut reconnaître de nouvelles classes sans avoir vu d'exemples explicites pendant l'entraînement.