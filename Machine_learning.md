[github perso](https://github.com/bruno-coulet/what-is-machine-learning)
[Machine learnia](https://www.youtube.com/watch?v=K9z0OD22My4&list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY&index=2)
[Machine learnia github](https://github.com/MachineLearnia/Python-Machine-Learning)
[StatQuest](https://www.youtube.com/watch?v=Gv9_4yMHFhI&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=1&t=46s)

## Conventions

matrice $m * n$<br>
- $m$ lignes (observations)
- $n$ colonnes (variables ou features)

| symbole  |signification | |   |
| - | -- | - | - |
| $y$ | target| | |
| $x_1$  $x_2$  $x_3$ ... | features ou variables || |
| $m$ | nombre d'observations | |  |
| $n$  | nombre de features ou    variables  |  |             |
| $x_3^{(2)}$<br><br>$x_{feature}^{(exemple)}$ | 3√®me feature de l'observation 2 | | |
| erreur  | √©cart entre valeur r√©elle et pr√©diction | $(f_{(x^i)} - y_i)^2$<br><br> ou <br><br> $(y_i - f_{(x^i)})^2$<br>     | $(\hat{y} - y_i)^2$<br><br> ou <br><br> $(y_i - \hat{y})^2$ |
| $J(a,b)$                                     | fonction co√ªt<br>param√®tre a et b                                             | somme (de $i$ √† $m$) de toutes les $(erreurs)^2$/ nombre d'observation | $$\frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y})^2$$          |

L‚Äô**erreur** peut √™tre exprim√©e au carr√© ou en valeur absolue, selon le contexte (MSE, MAE, ...)

## Intro
1. Dataset
2. modele
3. fonction de co√ªt
4. algorithme de minimisation, **descente de gradient**

## dataset
<img src="img/dataset.png" width=400>
<br>
La data est coup√©e en 2 ensembles Y et y :

- $X$ : variables explicatives (features) utilis√©es pour faire les pr√©dictions ($m \times n$)

- $y$ : variable cible (target) que l'on veut pr√©dire ( $m \times 1$)

### Dimensions des donn√©es

|R√¥le|Dimensions|Notation math√©matique|
| - | - | - |
| variable cible<br>**target** | matrice $m * n$<br>m lignes, 1 colonnes | $y \in \mathbb{R}^{m \times 1}$|
variables explicatives<br>**features** | matrice $m * n$<br>m lignes, n colonnes | $X \in \mathbb{R}^{m \times n}$ |

Avec `scikit-learn`, $y$ est souvent un vecteur de dimension $(m,)$

En `NumPy` $(m,)$ et $(m,1)$ n‚Äôont pas exactement le m√™me comportement :

- $(m,)$ est un vecteur 1D
- $(m,1)$ est une matrice 2D avec une seule colonne.

 **Cons√©quence pratique** :  
Certaines op√©rations NumPy (broadcasting, produits matriciels, concat√©nations) peuvent donner des r√©sultats diff√©rents selon la forme choisie.  
C‚Äôest pourquoi scikit-learn attend g√©n√©ralement un `y` en forme **1D**.

### Exemple NumPy : diff√©rences entre `(m,)` et `(m, 1)`

```python
import numpy as np

y_1d = np.array([1, 2, 3])
y_2d = np.array([[1], [2], [3]])

y_1d.shape  # (3,)
y_2d.shape  # (3, 1)
```
Diff√©rence cl√© :

(
ùëö
,
)
(m,) ‚Üí vecteur 1D

(
ùëö
,
1
)
(m,1) ‚Üí matrice colonne 2D

Op√©rations courantes :<br>
```python
X = np.ones((3, 2))

X @ y_1d   # OK ‚Üí r√©sultat (3,)
X @ y_2d   # OK ‚Üí r√©sultat (3, 1)
```

<img src="img/X_y.png" width=300>

|||
| - | - |
| $m$ | nombre d'observations (lignes du dataset)       |
| $n$ | nombre de variables explicatives (colonnes de $X$)           |
| $y$ | vecteur des cibles $m$                 |
| $X$ | matrice des variables explicatives $m \times n$ |



## exemple de modele
| *lin√©aire* | $$f_{(x)} = ax + b$$                           |
| -------------------------------- | ---------------------------------------------- |
| **fonction de co√ªt**<br>le $2m$ au d√©nominateur est pratique<br>pour le calul de la d√©riv√©e             | $$\frac{1}{2m} \sum_{i=1}^{m} (a.x + b -y)^2$$ |
| **algorithme de minimisation**   | **descente de gradient**                       |



## Etapes de travail


Pr√©dictions et classification



- fonction de co√ªt : mesure les erreurs entre les pr√©dictions du mod√®le et les valeurs du dataset
- algorithme de minimisation de la fonction de co√ªt en modifiant les param√®tres

---
## √âtapes de travail

<img src="img/linear_regression_pipeline.png" width=800>

### 1. Choix du mod√®le
On choisit une **famille de mod√®les** adapt√©e (r√©gression lin√©aire, polynomiale, etc.)

### 2. Jeux de donn√©es, on divise les donn√©es en trois ensembles :

- **Training set**  
  Entra√Æner le mod√®le, c‚Äôest-√†-dire √† ajuster les param√®tres pour minimiser l‚Äôerreur.

- **Validation set**  
  Tester diff√©rentes **configurations** ou **hyperparam√®tres**, et √† **√©viter le surapprentissage** (*overfitting*).

- **Testing set**  
  Evaluer la **performance finale** du mod√®le sur des donn√©es **jamais vues**.


### 3. Apprentissage
La machine **apprend** les **meilleurs param√®tres** (poids, coefficients) √† partir des donn√©es du **Training set**

### 4. √âvaluation du mod√®le

- **Fonction de co√ªt**  
  Mesure l‚Äôerreur entre les valeurs pr√©dites et les vraies valeurs.  


- **Algorithme de minimisation**  
  Trouve les meilleurs param√®tres en **minimisant la fonction de co√ªt**.  
  Exemple : **descente de gradient**







## Modele

modele lin√©aire univari√©
param√®tres $a$ et $b$
$m$ observation

|                                   Lin√©aire                                   |                                      Forme matricielle                                       | Param√®tres                                  |
| :--------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------: | ------------------------------------------- |
|                              $f_{(x)} = ax + b$                              |                                       $F = X . \theta$                                       | vecteur $\theta$                            |
|    $F = \begin{bmatrix}f_{(x^1)}\\f_{(x^2)}\\\dots\\f_{(x^m)}\\\end{bmatrix}$    |    $X = \begin{bmatrix}x^{(1)} & 1 \\x^{(2)} & 1\\\dots & \dots \\x^{(m)} & 1\\\end{bmatrix}$    |    $\theta = \begin{bmatrix}a\\b\end{bmatrix}$     |

 $f_{(x^1)} \qquad = \qquad a.x^{(1)} + b \qquad = \qquad a.x^{(1)} +  1 . b$ 


**Pour pouvoir faire le calcul matriciel $X \times \theta$

Les dimensions des 2 matrices doivent √™tre de type :
	  $m \times n$ 
	  $n \times \text{n'importe   quoi}$ 
  
il faut une dimension commune, ici $n$

Puisque le vecteur $\theta$ est de dimension $2 \times 1$
La matrice $X$ doit √™tre de dimension $m \times 2$

On ajoute donc la colonne de $1$ dans la matrice $X$
Ainsi elle passe de $m \times 1$  √† $m \times 2$ 


 - $n$ est le nombre de param√®tres
- la matrice $X$ est de dimension $m * (n+1)$
- le vecteur $\theta$ est de dimension $(n + 1) * 1$ 
- On ajoute toujours au mod√®le et au dataset ce +1 qui correspond √† une colonne de **biais**

pour obtenir toutes les valeurs de $f_{(x)}$
depuis $x = 1$
jusqu'a $x = m$ 


<img src="img/equations.png" width=600>


## Fonction de co√ªt J(Œ∏)
Mesure l'erreur entre les pr√©dictions du mod√®le et les vraies valeurs.
**Regression**
- MSE (Mean Squared Error ‚Äî erreur quadratique moyenne)
- MAE (Mean Absolute Error ‚Äî erreur absolue moyenne)
- **Huber loss** (combine MSE et MAE, plus robuste aux outliers)
**Classification binaire**
- Log loss / Cross-entropy
**Classification multi-classes
- Cross-entropy multi-classes

Sert √† entra√Æner le mod√®le en quantifiant l‚Äôerreur √† minimiser pendant l‚Äôapprentissage.

Soit pour $m$ √©l√©ments :

| Forme Lin√©aire                                                                                                                                       |                  | Forme matricielle                                    | dimension | $J(\theta) =$                          |
| ---------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------- | ---------------------------------------------------- | --------- | -------------------------------------- |
| $$\frac{1}{2m} \sum_{i=1}^{m} (a.x + b -y)^2$$                                                                                                       | $a.x + b$<br>    | $X.\theta$                                           | <br>$m*1$ | $$\frac{1}{2m} \sum (X.\theta - Y)^2$$ |
|                                                                                                                                                      | $-y$             | - vecteur $Y$  <br>                                  | $m*1$     |                                        |
|                                                                                                                                                      |                  | $X.\theta - Y$                                       | $m*1$     |                                        |
|                                                                                                                                                      | $(\dots)^2$      | chaque composante (donc le vecteur) est mis au carr√© | $m*1$     |                                        |
|                                                                                                                                                      | $\sum_{i=1}^{m}$ | on fait la somme de chaque √©l√©ment<br>               | $1*1$     |                                        |
| Le facteur $\frac{1}{2}$‚Äã est utilis√© pour simplifier les d√©riv√©es (dans la descente de gradient, le 2 issu de la d√©riv√©e du carr√© s‚Äôannule avec ce  | $\frac{1}{2m}$   | divis√© par $2m$                                      | $1*1$     | $\frac{1}{2}$                          |
|                                                                                                                                                      |                  |                                                      |           |                                        |

Utilise Testing Data pour √©valuer les mod√®le de Machine Learning.  

L'important n'est pas comment un mod√®le colle au Training data mais de savoir si les pr√©dictions sont justes.


<img src="img/testing-data.png" width=400>


## Descente de gradient
algorithme qui permet de **minimiser la fonction de co√ªt**
en ajustant les param√®tres du mod√®le $\theta$ pour r√©duire l'erreur.

| Forme matricielle                                                       |                                                                                                        |
| ----------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| $$\frac{\partial J(\theta)}{\partial \theta}$$<br>$(n + 1) * 1$<br><br> | Vecteur qui va calculer toutes les d√©riv√© de $J$ par rapport √† tous les param√®tres du vecteur $\theta$ |
| $$\frac{1}{m} X^\top (X\theta - Y)$$<br>                                |                                                                                                        |
|                                                                         |                                                                                                        |
| Œ±                                                                       | taux d‚Äôapprentissage (learning rate)                                                                   |
| $\frac{‚àÇJ(\theta)‚Äã}{‚àÇŒ∏_j}$‚Äã                                             | gradient (d√©riv√©e partielle du co√ªt)                                                                   |



## Cross Validation

Les data sont d√©coup√©es en n tranches
Certaines tranches sont destin√© √† l'entrainement, les tranches restantes sont r√©serv√©es pour le test.

**Comment choisir quelle tranche sert au test ?**

La <font color="orange">cross validation</font> consiste √† r√©server alternativement toutes les tranches de donn√©e aux test.
Au final, toutes les donn√©es ont servies √† l'entrainement et au test :

 Soit 4 tranches de donn√©es :
 
|||
|:-:|:-:|
| les 3 premi√®res tranches sont utilis√© pour l'entrainement | ![cross_validation_4](img/cv/cross_validation_train_4.png)|
| la 4√®me tranche est r√©serv√© aux tests |![cross_validation_4](img/cv/cross_validation_test_4.png)|
| on note les r√©sultats |![](img/cv/cross_validation_track_4.png)|
| puis c'est la 3√®me tranche qui est r√©serv√©e aux tests, on note les r√©sultats| ![](/img/cv/cross_validation_track_3.png)| 
| puis c'est la 2√®me tranche qui est r√©serv√©e aux tests, on note les r√©sultats| ![](/img/cv/cross_validation_test_2.png)| 

Enfin c'est la 1√®re tranche qui est r√©serv√©e aux tests, on note les r√©sultats et on les compile :
![](/img/cv/cross_validation.png)
Ainsi toutes les donn√©es ont servies √† l'entrainement et au test



Sert √† comparer diff√©rentes m√©thodes de Machine Learning :
- Logistic regression
- k-nearest neighbors
- support vector machines
<img src="img/cv/cross_validation_comparaison.png" width=400>
  

## Confusion Matrix
permet de calculer les m√©triques **Accuracy, Precision, Sensitivity,Specificity, F1-score**

 ```python
 confusion_matrix(y_train, y_pred)
 ```
Tableau √† n ligne et n colonne pour n param√®tres √† v√©rifier
Permet de d√©terminer ce que le mod√®le √† pr√©dit correctement (diagonale verte) et incorrectement (faux positifs et faux n√©gatifs en rouge)

**lignes** = classe r√©elles
**colonnes** = classe pr√©dites

|                 | classe pr√©dite 0                        | classe pr√©dite 1                        |
| --------------- | --------------------------------------- | --------------------------------------- |
| **classe r√©elle 0** | <font color = green>vrai n√©gatif</font> | <font color = red>faux positif</font>   |
| **classe r√©elle 1** | <font color = red>faux n√©gatif</font>   | <font color = green>vrai positif</font> |

## Metrique evaluation
R2, RMSE, MAE, accuracy, F1-score‚Ä¶

Formule du coefficient de d√©termination $R^2$
$$R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

- mesure la proportion de la variance de la variable cible expliqu√©e par le mod√®le.
  
- Peut √™tre n√©gatif si le mod√®le est pire que la moyenne des $y$

|           |                                                        |
| --------- | ------------------------------------------------------ |
| $R^2=1$   | pr√©diction parfaite                                    |
| $R^2 = 0$ | le mod√®le n‚Äôexplique pas mieux que la moyenne des $y$. |


| `precision_score(y_true, y_pred)`                                      |
| ---------------------------------------------------------------------- |

| Accuracy                                | F1-score                                                                                    |
| --------------------------------------- | ------------------------------------------------------------------------------------------- |
| Taux de pr√©dictions correctes           | Moyenne harmonique entre Precision et Recall                                                |
| $$ \frac{VP + VN}{VP + VN + FP + FN} $$ | $$ \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} $$ |
| % des cas bien class√©s                  | Mesure globale en cas de d√©s√©quilibre                                                       |
| `accuracy_score(y_true, y_pred)`        | `f1_score(y_true, y_pred)`                                                                  |

| Sensitivity (Recall)                         | Specificity                          | Precision                           |
| ------------------------------------------- | ------------------------------------ | ----------------------------------- |
| Taux de vrais positifs (TPR)                | Taux de vrais n√©gatifs (TNR)         | Taux sur les positifs pr√©dits       |
| $$ \frac{VP}{VP + FN} $$                    | $$ \frac{VN}{VN + FP} $$             | $$ \frac{VP}{VP + FP} $$            |
| % des cas positifs correctement d√©tect√©s    | % des cas n√©gatifs bien rejet√©s      | % des positifs pr√©dits corrects     |
| `recall_score(y_true, y_pred)`              | (√† calculer manuellement)            | `precision_score(y_true, y_pred)`   |

```python
from sklearn.metrics import confusion_matrix
tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
specificity = tn / (tn + fp)

```


<img src="img/classification/confusion_matrix/sensitivity.png" width=500>

**Sensitivity =**  Vrais positifs / (vrais positifsn + faux n√©gatifs)

<img src="img/classification/confusion_matrix/specificity.png" width=500>

**Specificity =**  Vrais n√©gatifs / (vrais n√©gatifs + faux positifs)

## ROC
**Receivor Operator Characteristic**
Aide √† choisir le meilleur seuil pour cat√©goriser les donn√©es

Essayons de savoir si une souris est ob√®se (1) ou pas (0) en sachant son poids

<img src="img/classification/logistic_regression/curve.png" width=400>

Les souris rouges ne sont pas ob√®ses (0)
Les souris bleues sont  ob√®ses (1)
<img src="img/classification/logistic_regression/mice.png" width=400>

Avec un seuil √† 0,5

| Classification   | Seuil  |
| ---------------- | ------ |
| souris ob√®se     | >= 0,5 |
| souris pas ob√®se | <= 0,5 |

<img src="img/classification/logistic_regression/log_reg_04.png" width=400>

**Comparaison des diff√©rent seuils**
Specificity = Vrais n√©gatifs / (vrais n√©gatifs + faux positifs)
Sensitivity =   Vrais positifs / (vrais positifs + faux n√©gatifs)

Comparaison des diff√©rent seuils
<img src="img/classification/logistic_regression/ROC.png" width=400>



## AUC
Area Under The Curve (ROC cuve)
<img src="img/classification/logistic_regression/AUC.png" width=400>

