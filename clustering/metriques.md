# üîç M√©triques de similarit√© en clustering non supervis√©

Dans le clustering non supervis√©, le choix d'une **m√©trique de similarit√© ou de distance** est essentiel pour d√©terminer la formation des clusters. Voici les principales m√©triques utilis√©es :

## üìê Distances pour donn√©es num√©riques

| Nom         | Formule                                                                 | Remarques                                                  |
|--------------|------------------------------------------------------------------------|-------------------------------------------------------------|
| Euclidienne $‚à•x‚à•$ | $$ d(x, y) = \sqrt{ \sum (x_i - y_i)^2 } $$                           | Standard, utilis√©e dans K-Means                             |
| Manhattan    | $$ d(x, y) = \sum \left\| x_i - y_i \right\| $$                         | Moins sensible aux outliers                                 |
| Minkowski    | $$ d(x, y) = \left( \sum_{i=1}^n \left\| x_i - y_i \right\|^p \right)^{1/p} $$ | Param√®tre $$ p $$ variable (1 = Manhattan, 2 = Euclidienne) |
| Mahalanobis  | Bas√©e sur la matrice de covariance                                    | Prend en compte les corr√©lations                            |




## üßæ Similarit√© pour donn√©es textuelles / binaires

| Nom         | Formule                                               | Utilisation typique                  |
|-------------|--------------------------------------------------------|--------------------------------------|
| Cosine      | $  \cos(\theta) = \frac{x \cdot y}{\|x\| \|y\|} $      | Texte, TF-IDF                        |
| Jaccard     | $  \frac{\|A \cap B\|}{\|A \cup B\|} $                     | Donn√©es binaires, ensembles          |
| Hamming     | $  \frac{\text{diff√©rences}}{n} $                    | Variables binaires ou cat√©gorielles  |

## üéØ Choix de la m√©trique selon le type de donn√©es

| Type de donn√©es            | M√©triques adapt√©es                  |
|----------------------------|-------------------------------------|
| Num√©riques continues       | Euclidienne, Manhattan              |
| Texte / vecteurs creux     | Cosine                              |
| Binaires                   | Jaccard, Hamming                    |
| Mixtes (num. + cat√©g.)     | Gower (ou combinaison personnalis√©e) |

---

## üß† Remarques

- Une **mauvaise m√©trique** peut conduire √† un **clustering incoh√©rent**
- Certaines m√©thodes (comme K-Means) supposent implicitement une distance euclidienne
- Des algorithmes comme **DBSCAN** ou **CAH** permettent d‚Äôutiliser d‚Äôautres m√©triques

